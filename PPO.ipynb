{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0ydodVdVK++V4mvsMtr04",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonali2824/RL-PROJECT/blob/main/PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRZOJxfK9u0r",
        "outputId": "fa30181f-d9f7-490d-bb89-cc7fb1f55c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/drive/MyDrive/PPO'"
      ],
      "metadata": {
        "id": "JfBVLAbe9-iV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ActorNetwork(nn.Module):\n",
        "    def __init__(self, obs_shape, action_shape):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(obs_shape[0]*obs_shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, action_shape)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.tensor(x, dtype=torch.float)\n",
        "        x = x.view(1, 105)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.softmax(self.fc3(x), dim=-1)\n",
        "        dist = torch.distributions.Categorical(logits=x)\n",
        "        return dist\n",
        "\n",
        "class CriticNetwork(nn.Module):\n",
        "    def __init__(self, obs_shape):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(obs_shape[0]*obs_shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.tensor(x, dtype=torch.float)\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        x = x.view(1, 105)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    \n",
        "#PPO \n",
        "class PPO:\n",
        "    def __init__(self, env):\n",
        "        self.env=env\n",
        "        self.obs_dimension=self.env.observation_space.shape\n",
        "        self.act_dimension=self.env.action_space.n\n",
        "\n",
        "        #actor critic network\n",
        "        self.actor=ActorNetwork(self.obs_dimension, self.act_dimension)\n",
        "        self.critic=CriticNetwork(self.obs_dimension)\n",
        "        self.lr = 0.005\n",
        "\n",
        "        # Initialize optimizers for actor and critic\n",
        "        self.actor_optimizer = Adam(self.actor.parameters(), lr=self.lr, eps=1e-5)  \n",
        "        self.critic_optimizer = Adam(self.critic.parameters(), lr=self.lr,eps=1e-5)\n",
        "        self.learn_rewards = []\n",
        "\n",
        "        self.logger = {\n",
        "\t\t\t'delta_t': time.time_ns(),\n",
        "\t\t\t't_so_far': 0,          # timesteps so far\n",
        "\t\t\t'i_so_far': 0,          # iterations so far\n",
        "\t\t\t'batch_lens': [],       # episodic lengths in batch\n",
        "\t\t\t'batch_rews': [],       # episodic returns in batch\n",
        "\t\t\t'actor_losses': [],     # losses of actor network in current iteration\n",
        "\t\t}\n",
        "        self.learn(1000000)\n",
        "        plt.plot(self.learn_rewards)\n",
        "        plt.show()\n",
        "\n",
        "    def learn(self, total_timesteps):\n",
        "        self.overall_rewards = []\n",
        "        self.timesteps_per_batch = 4800                 # Number of timesteps to run per batch\n",
        "        self.max_timesteps_per_episode = 1600           # Max number of timesteps per episode\n",
        "        self.n_updates_per_iteration = 5                # Number of times to update actor/critic per iteration\n",
        "        self.lr = 0.005                                 # Learning rate of actor optimizer\n",
        "        self.gamma = 0.95                               # Discount factor to be applied when calculating Rewards-To-Go\n",
        "        self.clip = 0.2                                 # Recommended 0.2, helps define the threshold to clip the ratio during SGA\n",
        "\n",
        "        # Miscellaneous parameters\n",
        "        self.render = False                              # If we should render during rollout\n",
        "        self.render_every_i = 10                        # Only render every n iterations\n",
        "        self.save_freq = 10                             # How often we save in number of iterations\n",
        "        self.seed = None                                # Sets the seed of our program, used for reproducibility of results\n",
        "        print(f\"Learning... Running {self.max_timesteps_per_episode} timesteps per episode, \", end='')\n",
        "        print(f\"{self.timesteps_per_batch} timesteps per batch for a total of {total_timesteps} timesteps\")\n",
        "        t_so_far = 0 # Timesteps simulated so far\n",
        "        i_so_far = 0 # Iterations ran so far\n",
        "        maxreward = []\n",
        "        while t_so_far < total_timesteps:                                                                       # ALG STEP 2\n",
        "            # Autobots, roll out (just kidding, we're collecting our batch simulations here)\n",
        "            batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens = self.rollout()                     # ALG STEP 3\n",
        "            maxreward.append(max(batch_rtgs))\n",
        "            print(\"max\")\n",
        "            if(len(maxreward)>5):\n",
        "                plt.plot(maxreward)\n",
        "                plt.savefig(folder+'\\episode_reward'+str(len(maxreward))+'.jpg')\n",
        "                plt.close()\n",
        "\n",
        "            # Calculate how many timesteps we collected this batch\n",
        "            t_so_far += np.sum(batch_lens)\n",
        "\n",
        "            # Increment the number of iterations\n",
        "            i_so_far += 1\n",
        "\n",
        "            # Logging timesteps so far and iterations so far\n",
        "            self.logger['t_so_far'] = t_so_far\n",
        "            self.logger['i_so_far'] = i_so_far\n",
        "\n",
        "            # Calculate advantage at k-th iteration\n",
        "            log_prob, V, entropy= self.evaluate(batch_obs, batch_acts)\n",
        "            A_k = batch_rtgs - V.detach()                                                                       # ALG STEP 5\n",
        "            A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10)\n",
        "            \n",
        "            # This is the loop where we update our network for some n epochs\n",
        "            for _ in range(self.n_updates_per_iteration):                                                       # ALG STEP 6 & 7\n",
        "                # Calculate V_phi and pi_theta(a_t | s_t)\n",
        "                curr_log_probs, V, curr_entropy = self.evaluate(batch_obs, batch_acts)\n",
        "\n",
        "                ratios = torch.exp(curr_log_probs - batch_log_probs)\n",
        "                ratios.requires_grad = True\n",
        "                A_k.requires_grad = True\n",
        "                # Calculate surrogate losses.\n",
        "                surr1 = ratios * A_k\n",
        "                surr2 = torch.clamp(ratios, 1 - self.clip, 1 + self.clip) * A_k\n",
        "\n",
        "                actor_loss = (-torch.min(surr1, surr2)).mean()\n",
        "                critic_loss = nn.MSELoss()(V, batch_rtgs)\n",
        "\n",
        "                # Calculate gradients and perform backward propagation for actor network\n",
        "                self.actor_optimizer.zero_grad()\n",
        "                actor_loss.backward(retain_graph=True)\n",
        "                self.actor_optimizer.step()\n",
        "\n",
        "                # Calculate gradients and perform backward propagation for critic network\n",
        "                self.critic_optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                self.critic_optimizer.step()\n",
        "\n",
        "                # Log actor loss\n",
        "                self.logger['actor_losses'].append(actor_loss.detach())\n",
        "\n",
        "            # Print a summary of our training so far\n",
        "            # self._log_summary()\n",
        "            print(\"End!\")\n",
        "\n",
        "            # Save our model if it's time\n",
        "            # if i_so_far % self.save_freq == 0:\n",
        "            print(\"path\", folder+'/ppo_actor.pth')\n",
        "            torch.save(self.actor.state_dict(), folder+'/ppo_actor.pth')\n",
        "            torch.save(self.critic.state_dict(), folder+'/ppo_critic.pth')\n",
        "            self.learn_rewards.append(np.mean(self.overall_rewards))\n",
        "            print(\"Plot\", self.overall_rewards)\n",
        "            # plt.plot(self.overall_rewards)\n",
        "            # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def rollout(self):\n",
        "\t\t\n",
        "        # Batch data. For more details, check function header.\n",
        "        batch_obs = []\n",
        "        batch_acts = []\n",
        "        batch_log_probs = []\n",
        "        batch_rews = []\n",
        "        batch_rtgs = []\n",
        "        batch_lens = []\n",
        "\n",
        "        # Episodic data. Keeps track of rewards per episode, will get cleared\n",
        "        # upon each new episode\n",
        "        ep_rews = []\n",
        "\n",
        "        t = 0 # Keeps track of how many timesteps we've run so far this batch\n",
        "\n",
        "        # Keep simulating until we've run more than or equal to specified timesteps per batch\n",
        "        while t < self.timesteps_per_batch:\n",
        "            ep_rews = [] # rewards collected per episode\n",
        "\n",
        "            # Reset the environment. sNote that obs is short for observation. \n",
        "            obs, info = self.env.reset()\n",
        "            done = truncated = False\n",
        "\n",
        "            # Run an episode for a maximum of max_timesteps_per_episode timesteps\n",
        "            for ep_t in range(self.max_timesteps_per_episode):\n",
        "                # If render is specified, render the environment\n",
        "                # if self.render and (self.logger['i_so_far'] % self.render_every_i == 0):# and len(batch_lens) == 0:\n",
        "                #     self.env.render()\n",
        "\n",
        "                t += 1 # Increment timesteps ran this batch so far\n",
        "\n",
        "                # Track observations in this batch\n",
        "                batch_obs.append(obs)\n",
        "\n",
        "                # Calculate action and make a step in the env. \n",
        "                # Note that rew is short for reward.\n",
        "                action, log_prob = self.get_action(obs)\n",
        "                #print(\"Action and log_prob\", action, log_prob)\n",
        "                obs, rew, done, truncated, info = self.env.step(action)\n",
        "                # Track recent reward, action, and action log probability\n",
        "                ep_rews.append(rew)\n",
        "                batch_acts.append(action)\n",
        "                batch_log_probs.append(log_prob)\n",
        "\n",
        "                # If the environment tells us the episode is terminated, break\n",
        "                if done or info[\"crashed\"]:\n",
        "                    break\n",
        "\n",
        "            # Track episodic lengths and rewards\n",
        "            batch_lens.append(ep_t + 1)\n",
        "            batch_rews.append(ep_rews)\n",
        "            self.overall_rewards.append(np.mean(ep_rews))\n",
        "\n",
        "        # Reshape data as tensors in the shape specified in function description, before returning\n",
        "        batch_obs = torch.tensor(batch_obs, dtype=torch.float)\n",
        "        batch_acts = torch.tensor(batch_acts, dtype=torch.float)\n",
        "        batch_log_probs = torch.tensor(batch_log_probs, dtype=torch.float)\n",
        "        batch_rtgs = self.compute_rtgs(batch_rews)                                                              # ALG STEP 4\n",
        "\n",
        "        # Log the episodic returns and episodic lengths in this batch.\n",
        "        # self.logger['batch_rews'] = batch_rews\n",
        "        # self.logger['batch_lens'] = batch_lens\n",
        "\n",
        "        return batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens\n",
        "    \n",
        "\n",
        "    def get_action(self, obs):\n",
        "        with torch.no_grad():\n",
        "            dist = self.actor(obs)\n",
        "            action = dist.sample()\n",
        "            log_prob = dist.log_prob(action)\n",
        "        return action.item(), log_prob\n",
        "    \n",
        "    def evaluate(self, obs, action):\n",
        "        obs = obs.view(obs.size()[0] * obs.size()[1], obs.size()[2])[:obs.size()[1],:]\n",
        "        with torch.no_grad():\n",
        "            dist = self.actor(obs)\n",
        "            log_prob = dist.log_prob(action)\n",
        "        value = self.critic(obs)\n",
        "        entropy = dist.entropy()\n",
        "        return log_prob, value, entropy\n",
        "\n",
        "    def compute_rtgs(self, batch_rews):\n",
        "        \"\"\"\n",
        "            Compute the Reward-To-Go of each timestep in a batch given the rewards.\n",
        "\n",
        "            Parameters:\n",
        "                batch_rews - the rewards in a batch, Shape: (number of episodes, number of timesteps per episode)\n",
        "\n",
        "            Return:\n",
        "                batch_rtgs - the rewards to go, Shape: (number of timesteps in batch)\n",
        "        \"\"\"\n",
        "        # The rewards-to-go (rtg) per episode per batch to return.\n",
        "        # The shape will be (num timesteps per episode)\n",
        "        batch_rtgs = []\n",
        "\n",
        "        # Iterate through each episode\n",
        "        for ep_rews in reversed(batch_rews):\n",
        "\n",
        "            discounted_reward = 0 # The discounted reward so far\n",
        "\n",
        "            # Iterate through all rewards in the episode. We go backwards for smoother calculation of each\n",
        "            # discounted return (think about why it would be harder starting from the beginning)\n",
        "            for rew in reversed(ep_rews):\n",
        "                discounted_reward = rew + discounted_reward * self.gamma\n",
        "                batch_rtgs.insert(0, discounted_reward)\n",
        "\n",
        "        # Convert the rewards-to-go into a tensor\n",
        "        batch_rtgs = torch.tensor(batch_rtgs, dtype=torch.float)\n",
        "\n",
        "        return batch_rtgs\n",
        "\n"
      ],
      "metadata": {
        "id": "vct0UJtX-eeT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment\n",
        "!pip install gymnasium\n",
        "import gymnasium as gym\n",
        "!pip install git+https://github.com/eleurent/highway-env#egg=highway-env\n",
        "import highway_env\n",
        "highway_env.register_highway_envs()\n",
        "\n",
        "# Agent\n",
        "!pip install git+https://github.com/eleurent/rl-agents#egg=rl-agents\n",
        "\n",
        "# Visualisation utils\n",
        "!pip install moviepy\n",
        "!pip install imageio_ffmpeg\n",
        "import sys\n",
        "%load_ext tensorboard\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb python-opengl ffmpeg\n",
        "!git clone https://github.com/eleurent/highway-env.git 2> /dev/null\n",
        "sys.path.insert(0, '/content/highway-env/scripts/')\n",
        "from utils import show_videos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdzG_vZ6-zmh",
        "outputId": "522ed3e7-de39-4bbb-9aa2-32ba011e93d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (1.22.4)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (6.3.0)\n",
            "Collecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium) (3.15.0)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting highway-env\n",
            "  Cloning https://github.com/eleurent/highway-env to /tmp/pip-install-6arhrsfa/highway-env_2eb700cbca41496d8e4b8d3fd68fa526\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/eleurent/highway-env /tmp/pip-install-6arhrsfa/highway-env_2eb700cbca41496d8e4b8d3fd68fa526\n",
            "  Resolved https://github.com/eleurent/highway-env to commit d7a95ddf5d438e378004a9df86d9d9739c0db7c8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from highway-env) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from highway-env) (1.22.4)\n",
            "Requirement already satisfied: gymnasium>=0.27 in /usr/local/lib/python3.9/dist-packages (from highway-env) (0.28.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from highway-env) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from highway-env) (3.7.1)\n",
            "Requirement already satisfied: pygame>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from highway-env) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.27->highway-env) (4.5.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.27->highway-env) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.27->highway-env) (6.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.27->highway-env) (2.2.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from gymnasium>=0.27->highway-env) (0.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->highway-env) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->highway-env) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium>=0.27->highway-env) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->highway-env) (1.16.0)\n",
            "Building wheels for collected packages: highway-env\n",
            "  Building wheel for highway-env (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for highway-env: filename=highway_env-1.8.1-py3-none-any.whl size=103792 sha256=79028f851ac8eef82789f94ac0bb2d9a0333f68bc3d7d851f954f82ab933ed65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gszvbrh5/wheels/24/34/ed/b4b2707e60527327929c9aea45f912af3c7ad8ecbb84f12a57\n",
            "Successfully built highway-env\n",
            "Installing collected packages: highway-env\n",
            "Successfully installed highway-env-1.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rl-agents\n",
            "  Cloning https://github.com/eleurent/rl-agents to /tmp/pip-install-111ujalk/rl-agents_fb2edf6d7ca845e08df8c4ff31ab044e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/eleurent/rl-agents /tmp/pip-install-111ujalk/rl-agents_fb2edf6d7ca845e08df8c4ff31ab044e\n",
            "  Resolved https://github.com/eleurent/rl-agents to commit cff61d5c2e166b3479647633aae4a2f65d9551d8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.9/dist-packages (from rl-agents) (0.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rl-agents) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from rl-agents) (1.5.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from rl-agents) (0.56.4)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.9/dist-packages (from rl-agents) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from rl-agents) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from rl-agents) (0.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from rl-agents) (1.16.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from rl-agents) (2.0.0+cu118)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from rl-agents) (1.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.2.0->rl-agents) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.2.0->rl-agents) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.2.0->rl-agents) (3.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium->rl-agents) (6.3.0)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium->rl-agents) (1.0.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from gymnasium->rl-agents) (0.0.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium->rl-agents) (2.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->rl-agents) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->rl-agents) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->rl-agents) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->rl-agents) (2022.7.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX->rl-agents) (3.20.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium->rl-agents) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.2.0->rl-agents) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.2.0->rl-agents) (1.3.0)\n",
            "Building wheels for collected packages: rl-agents, docopt\n",
            "  Building wheel for rl-agents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl-agents: filename=rl_agents-1.0.dev0-py3-none-any.whl size=112914 sha256=4fe88eab21b814b57e6df2f09f2c5d69354301464d9eab2571ae7acf5f913c6c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9zfu2x8v/wheels/2f/4f/9f/3a6fada1ed68d216d372eb0cfce5ce112f52f7f95e2d2dfd64\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=c2c1ae127effe4495fd3822c5ed645a3d4976a5c6d9d5e00bf096e5dd3cb887a\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "Successfully built rl-agents docopt\n",
            "Installing collected packages: docopt, tensorboardX, rl-agents\n",
            "Successfully installed docopt-0.6.2 rl-agents-1.0.dev0 tensorboardX-2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.9/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.9/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.9/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.9/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.9/dist-packages (0.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.9/dist-packages (2.6)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardx) (3.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardx) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardx) (23.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python2\n",
            "  python2-minimal x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  python-tk python-numpy libgle3 python2-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python-opengl\n",
            "  python2 python2-minimal x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 14 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 8,318 kB of archives.\n",
            "After this operation, 18.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 8,318 kB in 2s (5,109 kB/s)\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 122378 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../01-freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../03-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../04-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../05-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../06-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../08-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../10-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../11-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gymnasium as gym\n",
        "# import sys\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# import highway_env\n",
        "# import warnings\n",
        "# import time\n",
        "import pprint\n",
        "# # from PPO import PPO\n",
        "# # from PPO import ActorNetwork\n",
        "# from eval_policy import eval_policy\n",
        "# highway_env.register_highway_envs()\n",
        "\n",
        "from rl_agents.agents.common.factory import  load_environment\n",
        "\n",
        "# warnings.filterwarnings('ignore')\n",
        "def test(env, actor_model):\n",
        "\t\"\"\"\n",
        "\t\tTests the model.\n",
        "\n",
        "\t\tParameters:\n",
        "\t\t\tenv - the environment to test the policy on\n",
        "\t\t\tactor_model - the actor model to load in\n",
        "\n",
        "\t\tReturn:\n",
        "\t\t\tNone\n",
        "\t\"\"\"\n",
        "\tprint(f\"Testing {actor_model}\", flush=True)\n",
        "\n",
        "\t# If the actor model is not specified, then exit\n",
        "\tif actor_model == '':\n",
        "\t\tprint(f\"Didn't specify model file. Exiting.\", flush=True)\n",
        "\t\tsys.exit(0)\n",
        "\n",
        "\t# Extract out dimensions of observation and action spaces\n",
        "\tobs_dim = env.observation_space.shape\n",
        "\tact_dim = env.action_space.n\n",
        "\n",
        "\t# Build our policy the same way we build our actor model in PPO\n",
        "\tpolicy = ActorNetwork(obs_dim, act_dim)\n",
        "\tpolicy.load_state_dict(torch.load(actor_model))\n",
        "\tprint(\"eval\", policy.eval())\n",
        "\tfor name, param in policy.state_dict().items():\n",
        "\t\tif 'weight' in name:\n",
        "\t\t\tprint(name, param)\n",
        "\tprint(\"Policy\", policy)\n",
        "\n",
        "\t# Evaluate our policy with a separate module, eval_policy, to demonstrate\n",
        "\t# that once we are done training the model/policy with ppo.py, we no longer need\n",
        "\t# ppo.py since it only contains the training algorithm. The model/policy itself exists\n",
        "\t# independently as a binary file that can be loaded in with torch.\n",
        "\teval_policy(policy=policy, env=env, render=True)\n",
        "\n",
        "env_config = {\n",
        "    \"id\": \"intersection-v0\",\n",
        "    \"import_module\": \"highway_env\",\n",
        "    \"observation\": {\n",
        "        \"type\": \"Kinematics\",\n",
        "        \"vehicles_count\": 15,\n",
        "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\"],\n",
        "        \"features_range\": {\n",
        "            \"x\": [-100, 100],\n",
        "            \"y\": [-100, 100],\n",
        "            \"vx\": [-20, 20],\n",
        "            \"vy\": [-20, 20]\n",
        "        },\n",
        "        \"absolute\": True,\n",
        "        \"order\": \"shuffled\"\n",
        "    },\n",
        "    \"destination\":\"o1\"\n",
        "}\n",
        "\n",
        "\n",
        "env = load_environment(env_config)\n",
        "env.reset()\n",
        "pprint.pprint(env.config)\n",
        "\n",
        "def train():\n",
        "    print(\"train\")\n",
        "    #retrain\n",
        "    PPO(env)\n",
        "\n",
        "train()\n",
        "#test(env=env, actor_model=\"ppo_actor.pth\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9nF7WrU-7kV",
        "outputId": "2393476c-801f-461e-d653-15597acd3487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gymnasium/envs/registration.py:523: DeprecationWarning: \u001b[33mWARN: The environment intersection-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (15, 7)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'action': {'lateral': False,\n",
            "            'longitudinal': True,\n",
            "            'target_speeds': [0, 4.5, 9],\n",
            "            'type': 'DiscreteMetaAction'},\n",
            " 'arrived_reward': 1,\n",
            " 'centering_position': [0.5, 0.6],\n",
            " 'collision_reward': -5,\n",
            " 'controlled_vehicles': 1,\n",
            " 'destination': 'o1',\n",
            " 'duration': 13,\n",
            " 'high_speed_reward': 1,\n",
            " 'id': 'intersection-v0',\n",
            " 'import_module': 'highway_env',\n",
            " 'initial_vehicle_count': 10,\n",
            " 'manual_control': False,\n",
            " 'normalize_reward': False,\n",
            " 'observation': {'absolute': True,\n",
            "                 'features': ['presence',\n",
            "                              'x',\n",
            "                              'y',\n",
            "                              'vx',\n",
            "                              'vy',\n",
            "                              'cos_h',\n",
            "                              'sin_h'],\n",
            "                 'features_range': {'vx': [-20, 20],\n",
            "                                    'vy': [-20, 20],\n",
            "                                    'x': [-100, 100],\n",
            "                                    'y': [-100, 100]},\n",
            "                 'order': 'shuffled',\n",
            "                 'type': 'Kinematics',\n",
            "                 'vehicles_count': 15},\n",
            " 'offroad_terminal': False,\n",
            " 'offscreen_rendering': False,\n",
            " 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
            " 'policy_frequency': 1,\n",
            " 'real_time_rendering': False,\n",
            " 'render_agent': True,\n",
            " 'reward_speed_range': [7.0, 9.0],\n",
            " 'scaling': 7.15,\n",
            " 'screen_height': 600,\n",
            " 'screen_width': 600,\n",
            " 'show_trajectories': False,\n",
            " 'simulation_frequency': 15,\n",
            " 'spawn_probability': 0.6}\n",
            "train\n",
            "Learning... Running 1600 timesteps per episode, 4800 timesteps per batch for a total of 1000000 timesteps\n",
            "max\n",
            "End!\n",
            "path /content/drive/MyDrive/PPO/ppo_actor.pth\n",
            "Plot [-0.21978656437827895, 0.4776704302544069, 0.0, 0.16074837997854458, -0.30510668161424126, -0.3448330756460448, 0.5736573887652752, 0.25690500616564044, -0.5, 0.7124911910713623, -0.31556178532575574, -0.4, 0.4312462635939057, -0.4834511677642505, 0.31391879106834747, -0.2052817496748592, -0.27493696303016946, -0.5714285714285714, 0.4092254175292069, 0.3536589922282869, 0.0, 0.20873280128764038, 0.3696453337448705, 0.4693481916989485, -5.0, -5.0, -0.05616337726977749, 0.3979701980107675, -0.22776245952736054, 0.7552044459042451, 0.6282466961934161, -0.21978656437827895, 0.45592231766705343, -0.18099293932800908, -5.0, -0.5480122199340399, -0.26666666666666666, 0.2872350792537837, -0.2, 0.42608062233854127, -0.2, 0.0, -0.22993087442032115, 0.2684276527977155, 0.20200896483509911, 0.8741429566379818, 0.3068242049181964, -0.7273908589156157, 0.5017843023433314, -0.39553287194024084, -0.4, -0.43262814252797344, 0.09435364949125144, -0.4243096690308224, 0.6041378026249985, -0.5723559931470251, -0.16666666666666666, -1.0, 0.40455858236077286, -0.38639430863720303, 0.2590197476424192, 0.0, -0.4392390100733128, -0.4943765821918961, 0.7772892452458304, 1.0, -0.2, 0.2818332657172307, -0.406093049733354, -0.23520789654173488, 0.045629012955600796, 0.20104161959590616, -0.16118221092174373, 0.16944835461518024, -0.3125, 0.4102645309892823, -0.0544519570599948, 0.8616025321959097, -0.3125, -0.14285714285714285, -0.2114711962843084, 0.470032717443578, 0.7772631175323952, -0.14430626873826027, 0.17434194563941494, -0.3033003345804432, -0.39488247310450264, 0.25482441688660473, -0.11114119045724502, -0.39488247310450264, 0.2352430875335935, 0.17646797638148148, 0.6225851129130386, 0.2677446827059059, -0.04553997159244411, 0.312600845581643, -0.351231252699901, 0.23809523809523808, -0.24669827248786438, -0.2, -0.21978656437827895, -0.3136540851516635, 0.5817648353041582, 0.2152509682575637, 0.28919225757007555, 0.22353068888680347, 0.3683892841212073, 0.5394187657036539, 0.25125886793297353, 0.5527082672545205, 0.6225851129130386, -0.22879513836775578, -0.22776245952736054, -0.5, -0.2028595611423156, 0.2850061697846289, -0.05998469793242478, -0.24498205029755055, -0.4479770361547864, -0.18107942715109396, 0.24210405909434365, -0.6632594093503406, -0.05998469793242478, -0.2, -0.4445359496515078, -0.3157913308047472, 0.4307749858893711, -0.11354043701081092, 0.3273113852110321, -0.2222222222222222, 0.3608735891193783, -0.5621406161991649, -0.04553997159244411, 0.26563530967874993, 0.3740013887906491, 0.30873650688345156, 0.34488504358091115, 0.44303031569403534, 0.6946776434179659, -0.2637438772539348, -0.1111111111111111, -0.18181818181818182, 0.24116832756603787, -0.2, -0.3, -0.20677805344571112, -0.22879513836775578, -0.08367927739189324, 0.3410678124643135, -0.11265134153224372, 0.38369282496924334, -0.47824342876570103, 0.35326715839203604, 0.8481237690464559, -0.2277492009392726, -0.017347775472276023, 0.4471848766198117, 0.5079920262248633, -0.1608841923353327, 0.7, 1.0, -0.25, -0.2, 0.6604769418864583, -0.2052817496748592, 0.9, 0.1743203122612414, -0.49249411803299964, 0.1659820885322153, 0.25226595237908955, -0.2857142857142857, 0.19866912948501309, 0.38060221033820085, -0.2, -0.3333333333333333, 0.6923701562437085, -0.15349963021259022, -0.6167324677040035, -0.18838848375281053, -0.406093049733354, 0.17857142857142858, -0.5, 0.3617700859681388, 0.46782667871112804, 1.0, -0.33786524559193726, 0.7552044459042451, -0.18518518518518517, 0.2802328494689547, 0.3756994961637866, 0.567893529144771, -0.22993087442032115, 0.8462130204660376, -0.22879513836775578, 0.3482898802930014, -0.18181818181818182, -0.44162947424809873, 0.6634095065466414, -0.17454194982903698, -0.526718570740066, 0.8462301909645326, 0.4231150954822663, 0.2969831882966363, 0.290438952720161, 0.4441644427123635, -0.06219746325507088, 0.2225764567850435, -0.061139028666933104, -0.18838848375281053, 0.39827652903464844, 0.8617422832245097, 0.3256889215905436, 0.5239914146343662, 0.42634390963728136, -0.25, 0.11373225328914115, 0.6227814184818264, 0.28733740431821486, 1.0, 0.7250460038390752, 0.5963595817804087, 0.0, -0.43126557654911424, 0.0, -0.2, -0.5593622496261089, 0.2919354945962487, 0.6187576981654789, -0.3105061254387904, -0.2, 0.0, -0.44162947424809873, 0.38221867548946153, 0.2804310126425878, 0.20321183013717828, -0.22494842429741138, 0.4094747206647012, -0.18181818181818182, 0.22091124914786242, 1.0, 0.116668845786095, 0.22471727996330668, 0.69249275356068, 0.4442274957273531, 0.32498280901633697, -0.11598393282904595, 0.0, 0.47004357471787583, -0.3912900780810281, -5.0, 0.7297049998169661, 1.0, 0.3044119207483361, 0.5431670466429688, -0.5188380476480493, 0.2028769240599547, -0.47651002923350605, 0.4669163043516917, 0.4881826462637404, -0.22993087442032115, -0.2875125062655995, 1.0, 0.3939832798489922, 0.410576449083004, -5.0, 0.23736450963497419, -0.4444444444444444, -0.24731729274922717, 0.3907619819652213, 0.4269763832185985, -0.35714285714285715, -0.4730113438287121, 0.4017225218195959, -0.05998469793242478, 0.5984590637244288, 0.36798547381546326, 0.116668845786095, 0.46135755405030393, -0.2, -0.22879513836775578, -0.8290742616879256, 0.0, 0.2678045694674266, 0.2272372167103196, 0.2521122045667648, 0.29487315510918993, 0.5017880677362856, 0.7681208110378239, -0.16824979613716487, -0.22776245952736054, -0.3366622682497642, 0.0993411507437865, -0.1111111111111111, 0.0, 1.0, -0.4, 0.43082732987737943, 0.7842482115588769, 0.1512753910156133, -0.4392390100733128, 0.23729574751166674, 0.39545656843043897, 0.6292991732530298, -0.6578631187782907, 0.0967741935483871, 0.3031564497057702, -0.25, 0.4693715867605262, 0.723751132063878, 0.0, -0.38461538461538464, -0.05331211136148933, 0.16698399098675315, -0.4444444444444444, 0.0, 0.0, 0.30771272607302697, -0.3, -0.23529411764705882, 0.2267199997748769, 0.17824363953092132, 0.3440139818902949, 0.5691002943296037, -0.4445359496515078, 0.4969088151239506, -0.39553287194024084, -0.1875, -0.38639430863720303, 0.38043141694446864, 0.03646096224653734, -0.2038505367460807, 0.5860400358711035, 0.1442568876783345, -0.2966802291582365, -0.1905526769521989, 0.8465022740360384, -0.14092511464591673, 0.29214173588640946, -0.2052817496748592, -0.1400197688513425, -0.2857142857142857, -0.5351279015142663, -0.29654783396611983, 0.23741903488110627, 0.5079920262248633, -0.3271432911650984, -0.11598393282904595, -2.0, 0.0, 0.466215308528336, -0.34969611079355517, 0.1754501191970814, 0.5382443226057501, 0.7306361385274383, -0.406093049733354, -0.8390433744391634, 0.14994200744389669, -0.1724137931034483, -0.5, -0.38639430863720303, 0.4363511515117306, 0.6401006758648533, -0.2, 0.4140915843789167, -0.1952249653091662, 0.0, -0.7173651431485516, 0.2982833699444532, -0.24731729274922717, -0.40749393662076167, -0.4740696981377125, -0.04553997159244411, -0.08, -0.2318443906813108, -0.21634249814243167, -0.5099232299505329, -0.11897257939832083, -0.23089013522617427, -0.2, 0.46235200142923194, -0.5, -0.2, 0.43099361921761936, 0.5230197367353745, -0.2807430520943931, 0.46958039898302045, -0.4740696981377125, -0.16933057059042841, 0.4101354315757929, -0.22108646978344684, 0.5448934906214853, -0.2652744140326885, 0.5984590637244288, -0.22435923941207292, 0.2547726683658275, -0.19692276300775274, 0.14675520198496073]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4819])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max\n",
            "End!\n",
            "path /content/drive/MyDrive/PPO/ppo_actor.pth\n",
            "Plot [-0.21978656437827895, 0.4776704302544069, 0.0, 0.16074837997854458, -0.30510668161424126, -0.3448330756460448, 0.5736573887652752, 0.25690500616564044, -0.5, 0.7124911910713623, -0.31556178532575574, -0.4, 0.4312462635939057, -0.4834511677642505, 0.31391879106834747, -0.2052817496748592, -0.27493696303016946, -0.5714285714285714, 0.4092254175292069, 0.3536589922282869, 0.0, 0.20873280128764038, 0.3696453337448705, 0.4693481916989485, -5.0, -5.0, -0.05616337726977749, 0.3979701980107675, -0.22776245952736054, 0.7552044459042451, 0.6282466961934161, -0.21978656437827895, 0.45592231766705343, -0.18099293932800908, -5.0, -0.5480122199340399, -0.26666666666666666, 0.2872350792537837, -0.2, 0.42608062233854127, -0.2, 0.0, -0.22993087442032115, 0.2684276527977155, 0.20200896483509911, 0.8741429566379818, 0.3068242049181964, -0.7273908589156157, 0.5017843023433314, -0.39553287194024084, -0.4, -0.43262814252797344, 0.09435364949125144, -0.4243096690308224, 0.6041378026249985, -0.5723559931470251, -0.16666666666666666, -1.0, 0.40455858236077286, -0.38639430863720303, 0.2590197476424192, 0.0, -0.4392390100733128, -0.4943765821918961, 0.7772892452458304, 1.0, -0.2, 0.2818332657172307, -0.406093049733354, -0.23520789654173488, 0.045629012955600796, 0.20104161959590616, -0.16118221092174373, 0.16944835461518024, -0.3125, 0.4102645309892823, -0.0544519570599948, 0.8616025321959097, -0.3125, -0.14285714285714285, -0.2114711962843084, 0.470032717443578, 0.7772631175323952, -0.14430626873826027, 0.17434194563941494, -0.3033003345804432, -0.39488247310450264, 0.25482441688660473, -0.11114119045724502, -0.39488247310450264, 0.2352430875335935, 0.17646797638148148, 0.6225851129130386, 0.2677446827059059, -0.04553997159244411, 0.312600845581643, -0.351231252699901, 0.23809523809523808, -0.24669827248786438, -0.2, -0.21978656437827895, -0.3136540851516635, 0.5817648353041582, 0.2152509682575637, 0.28919225757007555, 0.22353068888680347, 0.3683892841212073, 0.5394187657036539, 0.25125886793297353, 0.5527082672545205, 0.6225851129130386, -0.22879513836775578, -0.22776245952736054, -0.5, -0.2028595611423156, 0.2850061697846289, -0.05998469793242478, -0.24498205029755055, -0.4479770361547864, -0.18107942715109396, 0.24210405909434365, -0.6632594093503406, -0.05998469793242478, -0.2, -0.4445359496515078, -0.3157913308047472, 0.4307749858893711, -0.11354043701081092, 0.3273113852110321, -0.2222222222222222, 0.3608735891193783, -0.5621406161991649, -0.04553997159244411, 0.26563530967874993, 0.3740013887906491, 0.30873650688345156, 0.34488504358091115, 0.44303031569403534, 0.6946776434179659, -0.2637438772539348, -0.1111111111111111, -0.18181818181818182, 0.24116832756603787, -0.2, -0.3, -0.20677805344571112, -0.22879513836775578, -0.08367927739189324, 0.3410678124643135, -0.11265134153224372, 0.38369282496924334, -0.47824342876570103, 0.35326715839203604, 0.8481237690464559, -0.2277492009392726, -0.017347775472276023, 0.4471848766198117, 0.5079920262248633, -0.1608841923353327, 0.7, 1.0, -0.25, -0.2, 0.6604769418864583, -0.2052817496748592, 0.9, 0.1743203122612414, -0.49249411803299964, 0.1659820885322153, 0.25226595237908955, -0.2857142857142857, 0.19866912948501309, 0.38060221033820085, -0.2, -0.3333333333333333, 0.6923701562437085, -0.15349963021259022, -0.6167324677040035, -0.18838848375281053, -0.406093049733354, 0.17857142857142858, -0.5, 0.3617700859681388, 0.46782667871112804, 1.0, -0.33786524559193726, 0.7552044459042451, -0.18518518518518517, 0.2802328494689547, 0.3756994961637866, 0.567893529144771, -0.22993087442032115, 0.8462130204660376, -0.22879513836775578, 0.3482898802930014, -0.18181818181818182, -0.44162947424809873, 0.6634095065466414, -0.17454194982903698, -0.526718570740066, 0.8462301909645326, 0.4231150954822663, 0.2969831882966363, 0.290438952720161, 0.4441644427123635, -0.06219746325507088, 0.2225764567850435, -0.061139028666933104, -0.18838848375281053, 0.39827652903464844, 0.8617422832245097, 0.3256889215905436, 0.5239914146343662, 0.42634390963728136, -0.25, 0.11373225328914115, 0.6227814184818264, 0.28733740431821486, 1.0, 0.7250460038390752, 0.5963595817804087, 0.0, -0.43126557654911424, 0.0, -0.2, -0.5593622496261089, 0.2919354945962487, 0.6187576981654789, -0.3105061254387904, -0.2, 0.0, -0.44162947424809873, 0.38221867548946153, 0.2804310126425878, 0.20321183013717828, -0.22494842429741138, 0.4094747206647012, -0.18181818181818182, 0.22091124914786242, 1.0, 0.116668845786095, 0.22471727996330668, 0.69249275356068, 0.4442274957273531, 0.32498280901633697, -0.11598393282904595, 0.0, 0.47004357471787583, -0.3912900780810281, -5.0, 0.7297049998169661, 1.0, 0.3044119207483361, 0.5431670466429688, -0.5188380476480493, 0.2028769240599547, -0.47651002923350605, 0.4669163043516917, 0.4881826462637404, -0.22993087442032115, -0.2875125062655995, 1.0, 0.3939832798489922, 0.410576449083004, -5.0, 0.23736450963497419, -0.4444444444444444, -0.24731729274922717, 0.3907619819652213, 0.4269763832185985, -0.35714285714285715, -0.4730113438287121, 0.4017225218195959, -0.05998469793242478, 0.5984590637244288, 0.36798547381546326, 0.116668845786095, 0.46135755405030393, -0.2, -0.22879513836775578, -0.8290742616879256, 0.0, 0.2678045694674266, 0.2272372167103196, 0.2521122045667648, 0.29487315510918993, 0.5017880677362856, 0.7681208110378239, -0.16824979613716487, -0.22776245952736054, -0.3366622682497642, 0.0993411507437865, -0.1111111111111111, 0.0, 1.0, -0.4, 0.43082732987737943, 0.7842482115588769, 0.1512753910156133, -0.4392390100733128, 0.23729574751166674, 0.39545656843043897, 0.6292991732530298, -0.6578631187782907, 0.0967741935483871, 0.3031564497057702, -0.25, 0.4693715867605262, 0.723751132063878, 0.0, -0.38461538461538464, -0.05331211136148933, 0.16698399098675315, -0.4444444444444444, 0.0, 0.0, 0.30771272607302697, -0.3, -0.23529411764705882, 0.2267199997748769, 0.17824363953092132, 0.3440139818902949, 0.5691002943296037, -0.4445359496515078, 0.4969088151239506, -0.39553287194024084, -0.1875, -0.38639430863720303, 0.38043141694446864, 0.03646096224653734, -0.2038505367460807, 0.5860400358711035, 0.1442568876783345, -0.2966802291582365, -0.1905526769521989, 0.8465022740360384, -0.14092511464591673, 0.29214173588640946, -0.2052817496748592, -0.1400197688513425, -0.2857142857142857, -0.5351279015142663, -0.29654783396611983, 0.23741903488110627, 0.5079920262248633, -0.3271432911650984, -0.11598393282904595, -2.0, 0.0, 0.466215308528336, -0.34969611079355517, 0.1754501191970814, 0.5382443226057501, 0.7306361385274383, -0.406093049733354, -0.8390433744391634, 0.14994200744389669, -0.1724137931034483, -0.5, -0.38639430863720303, 0.4363511515117306, 0.6401006758648533, -0.2, 0.4140915843789167, -0.1952249653091662, 0.0, -0.7173651431485516, 0.2982833699444532, -0.24731729274922717, -0.40749393662076167, -0.4740696981377125, -0.04553997159244411, -0.08, -0.2318443906813108, -0.21634249814243167, -0.5099232299505329, -0.11897257939832083, -0.23089013522617427, -0.2, 0.46235200142923194, -0.5, -0.2, 0.43099361921761936, 0.5230197367353745, -0.2807430520943931, 0.46958039898302045, -0.4740696981377125, -0.16933057059042841, 0.4101354315757929, -0.22108646978344684, 0.5448934906214853, -0.2652744140326885, 0.5984590637244288, -0.22435923941207292, 0.2547726683658275, -0.19692276300775274, 0.14675520198496073, -0.38639430863720303, 0.47044707892760934, -0.3130109514297719, 0.8462130204660376, 0.40356719255732065, -0.35714285714285715, -0.44608063150589733, -0.2, 0.5399752212514027, -0.2, 1.0, -0.21978656437827895, -0.4794533568223791, -0.673355181361912, -0.2052817496748592, -0.3844493711828054, -0.3995755062844621, 0.5860400358711035, 1.0, 0.5681905631501294, 0.717970448282255, 0.5708472748831604, 0.0, 0.623172516752652, 0.6083895645589245, -0.3684774496390781, 0.6859671351883474, -0.20642009785429183, 0.5543616660833834, -0.18845625008853092, -0.40749393662076167, -0.22776245952736054, -0.22993087442032115, 0.3587731045939058, -0.4636731703646436, -0.2857142857142857, 0.23982001390602448, -0.21978656437827895, -0.2196513994620618, -0.16666666666666666, 0.18469842771848718, 0.21191680982453068, 0.25666741378280006, 0.2900515203933788, 0.44316759852020127, -0.20379097273189176, -0.5, 1.0, 0.1374625462771331, 0.8534675678198044, 0.2484514965518602, -0.20677805344571112, -0.14285714285714285, -0.375, 0.1687161432671444, -0.19078533104900838, -0.5, -0.21563779964694207, -0.5, 0.43154903072938905, -0.0625, -0.2753494238698457, 1.0, 0.27113127282404914, -0.5, -0.4730113438287121, 0.24677171046268315, -0.05331211136148933, 1.0, -0.2, -0.2, 0.533937029555679, -0.47077244741430313, 0.35735285329464467, 0.2322803213617336, 0.7250792320216644, 0.28054448129031284, -0.22776245952736054, 0.0, -0.25, 0.15384986391866776, -0.2647296965934109, 0.532677419811167, 0.5508865663567414, -0.3, -0.5, -0.30463063933905854, -0.11375547657547876, 0.6517811200796694, -0.6745687394389979, -0.20905221835550325, 0.0, -0.6167324677040035, 0.2857142857142857, -0.5956474427954599, -0.2746805186682958, -0.36540219763247084, 0.3764781217997967, 0.41180629889644293, -0.3848080805114683, -0.2528638645694842, 0.2915410016491999, -0.3333333333333333, 0.6633670449578785, 0.5849736137746161, -0.2, -0.06219746325507088, 0.09107582673177207, 0.5932569836660259, -0.5345011200788905, 0.6024652921738122, 0.07142857142857142, 0.13612666098413628, 0.4458167539130399, 0.23392609613252396, -0.5, 0.0, 0.5333333333333333, 0.8463816913572154, -0.2318365851823218, -0.22776245952736054, 0.39910057508452346, 0.9, 0.24443754729239203, 0.8617422832245097, -0.526718570740066, -0.2, 0.8633112626830922, 0.6633121497054796, 0.12215897696585855, -0.20677805344571112, -0.2, 0.7550194139195963, 0.472579988823794, 0.6216502868648499, -0.11538461538461539, 0.7550194139195963, -0.5, -0.23422120128523033, -0.0793258898203282, -0.34498187386926027, -0.2857142857142857, 0.47722927676151006, -0.22879513836775578, 0.3228733280701595, 0.5513619351660735, -0.05, 0.29721957491182466, -0.22993087442032115, 0.23921080676307124, -0.21481154373968958, -0.2052817496748592, 0.22095548382868266, 0.8465022740360384, 0.5961598116538185, 0.0, -0.37661271472238145, 0.2937687197527502, -0.6666666666666666, -0.3, 0.08, -0.2, 0.6606145344339692, -0.21978656437827895, 0.5008778818403458, 0.0, -0.22993087442032115, 0.14199186216699217, 0.5045515715929789, 0.5015194181795509, 0.4686193513692404, 0.14865896708801182, -0.2962935613360703, 0.5439940845853098, 0.6297824997160579, -0.44608063150589733, 0.5239914146343662, 0.04558221305406431, 0.4751606454552152, 0.3929224854160183, -0.2222222222222222, 0.2978869256138571, 0.1586604434853081, -0.406093049733354, 0.4313120509754353, 0.21844599206889112, 0.401574254213302, -0.4636731703646436, -0.4943765821918961, -0.6632594093503406, 0.2851767099950577, -0.2164587766320688, 0.7777777777777778, 0.7257553354808604, 0.39663356160977703, 0.2443613796707701, -0.42857142857142855, -0.22776245952736054, -0.40749393662076167, -0.4444444444444444, -0.23529411764705882, 0.0, 0.7297504572013056, -0.2465705274536018, 0.35810244929799173, 0.23665314574665466, 0.25567105645178734, 0.6859671351883474, 0.33997397523236494, -0.6894917652461995, 0.47244253081020665, 0.861584437934706, -0.31224658068816, 0.26620433579831004, 0.6351149001630834, 0.2809401085531441, -0.9461482733004445, 0.0, 0.14899982234911033, 0.8616025321959097, 0.18249036574246244, 0.7300606313424166, -0.22572987001419126, 0.5503533680193493, -0.13636363636363635, 0.3433042605811916, -0.04064819431482922, -0.17647058823529413, 0.5357852009040118, 1.0, -0.4407210093071991, -0.19077201399394017, 0.24843348294082132, -0.6745687394389979, -0.22079359901952023, -0.24291176487328592, 0.5460035275935985, 0.2643713777499079, -0.47463944632828897, 0.3623954660310411, -0.2, 0.1994158732001831, 0.21632185851668767, -0.05331211136148933, -0.4740696981377125, -0.4654610285279568, 0.7626729963511277, 0.34877354160364077, -0.27044421942646274, -0.5, 0.3682214765275441, 0.4971353734201424, -0.6868271917764301, -0.25, 0.396782375506135, 0.0, 0.17253598427526126, -0.23076923076923078, -0.3333333333333333, -0.2515843404932692, -0.31362939185211425, -0.30730559599599055, 0.3243714564278668, 0.0, 0.33986969334326494, 0.14066386578057982, -0.22993087442032115, 0.5452224229584359, 0.75, -0.4394718565680019, 0.24652498098624187, -0.1898785418065975, -0.23809523809523808, -0.33786524559193726, 0.8462130204660376, -0.22776245952736054, 0.0, 0.29230289704719464, 0.6282732181659288, 0.14285714285714285, 0.39728805849534665, -0.28194478235747833, -0.5, -0.19506923857914366, 0.1977219338189071, -0.2857142857142857, 0.622746792077141, 1.0, 0.8474147103250819, 0.3799870918639081, -0.4, 0.5954708369225911, -0.3762612622881385, 0.4772049450132133, 0.6594561917359175, 0.6475493691060479, 0.11029898303444223, 0.6666666666666666, -0.4195216872195817, -0.18771978307020185, -0.3452437956687785, 0.23356308151631852, -0.21978656437827895, -0.30175889677339907, -0.27440921263202406, 0.7549948680373085, 0.2145740087391534, 0.7250792320216644, 0.321294402695138, -0.3747604107994433, 0.4382752515519062, 0.3131685088733197, -0.38253232428957673, -0.39417611985726014, 0.23118638454776985, 1.0, 0.34006840789761605, 0.44119219494196293, 0.2323556108519957, 0.5384615384615384, -0.2052817496748592, 0.0, 0.0, 0.2948296771414712, 0.17760220166324542, 0.3420818820221998, -0.2857142857142857, 0.0797806687387916, 0.3333333333333333, -0.30869645303773313, 0.40224234269916204, 0.11336749004677224, -0.5, -0.24229601197720146, 0.5451417297230338, 1.0, 0.7300606313424166, 0.19117873869450283, -0.04585427150019983, -0.6868271917764301, 1.0, 0.2077648387245209, -0.6, -0.1282051282051282, -0.2857142857142857, -0.3390281759487778, -0.40749393662076167, -0.6666666666666666, 0.25, -0.28853684154076503, -0.4243929764764796, 0.0, -0.6745687394389979, 0.11439080345358825, 0.35919049538854864, 0.2435383773575508, -0.23076923076923078, -0.16666666666666666, 0.6572635159806794, -0.24577820987672508, 1.0, 0.09300976152482478, -0.18181818181818182, -0.2805360774324477, -0.19972067678306207, -0.5380238573614137, -0.2122324386021186, 0.5328695734716555, 0.37089969048385196, -0.125, 0.20757476527525784, 0.18735542270160258, 0.21249606039031385, -0.36631043853487505, 0.6257826516344239, -0.31383025353138466, 0.7306361385274383, -0.4636731703646436, -0.3390281759487778, -0.2, -0.25941902382402465, -0.1911185612800914, -0.17244815581524087, 0.2728010763072115, 0.7549948680373085, -0.19867158600561244, -0.42441761166510394, 0.16509170981799973, -0.009438015177058045, 0.2808570981662622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4818])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    }
  ]
}